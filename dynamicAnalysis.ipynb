{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22120249f2a9466d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup\n",
    "\n",
    "In this example, as in others, we will be running our examples on the covasim package. This code assumes that the notebook sits within the Covasim repository.\n",
    "\n",
    "For your work you will be running this on your own code, so any calls to CovaSim will need to be replaced with calls to suitable entry-points within your own system.\n",
    "\n",
    "The nice thing here is that we are not relying on scrutinising the source code itself. You can install (via `pip install`) the project you are interested in analysing. This is what we do here.\n",
    "\n",
    "One major caveat is that the version you analyse _must_ correspond to the version you are using for the rest of your analyses (e.g. for static analysis). If the version you install via pip is different, then you will get inconsistent results.\n",
    "\n",
    "This is our setup code. We'll be offering four types of dynamic analysis, as defined in the Outputs class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f4af8b5c251c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by installing the external projects we will need for this.\n",
    "\n",
    "%pip install covasim graphviz pandas plotly networkx matplotlib stumpy nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb9e968cdf7776",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Outputs(Enum):\n",
    "    CALLS = 1  # Call graph, stored as a dot graph.\n",
    "    LINES = 2  # Record every single line encountered as a list.\n",
    "    PHASES = 3  # Record the stack depth at each method call, store as CSV.\n",
    "\n",
    "\n",
    "class PhaseData(Enum):\n",
    "    STACK_DEPTH = 1  # Call stack depth at every line.\n",
    "    MEM_USAGE = 2  # Memory usage at every line\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"outputType\": Outputs.CALLS,\n",
    "    \"phaseType\": PhaseData.STACK_DEPTH,\n",
    "    \"fileNameFilter\": \"covasim\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca25a2396ac09b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tracer code\n",
    "\n",
    "The following block contains the actual tracer code. trace_calls is the actual function that we attach to the tracer, so this is called every time a traceable event is encountered.\n",
    "\n",
    "It is worth pointing out how succinct and customisable this is. You can get the tracer to store any of the data in whichever way you want, in the space of a couple of small functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "import psutil\n",
    "\n",
    "# These data structures will contain the trace data at any given point.\n",
    "# Important that these are reset before every fresh trace!\n",
    "\n",
    "# If building a call graph, this is stored as a dictionary, where the key\n",
    "# is a function, and the value is a list of destination functions.\n",
    "trace = {}\n",
    "\n",
    "# Lines are stored as a list, if tracer is activated in Line-tracing mode\n",
    "lines = []\n",
    "\n",
    "phases = []\n",
    "\n",
    "\n",
    "def is_system_code(filename):\n",
    "    \"\"\"Check if the filename belongs to system or third-party libraries.\"\"\"\n",
    "    return not config[\"fileNameFilter\"] in filename\n",
    "\n",
    "\n",
    "def reset():\n",
    "    trace.clear()\n",
    "    lines.clear()\n",
    "    phases.clear()\n",
    "\n",
    "\n",
    "# Utility function to store calls. Key is source method, value is a set of target methods.\n",
    "def add_to_set(trace, key, value):\n",
    "    if key not in trace:\n",
    "        trace[key] = set()\n",
    "    trace[key].add(value)\n",
    "    return trace\n",
    "\n",
    "\n",
    "def trace_lines(frame, event, arg):\n",
    "    \"\"\"\n",
    "    Called for every line.\n",
    "    \"\"\"\n",
    "    if event == \"line\":\n",
    "        co = frame.f_code\n",
    "        func_filename = os.path.basename(co.co_filename)\n",
    "        if not config[\"fileNameFilter\"] in co.co_filename:\n",
    "            return\n",
    "        func_name = co.co_name\n",
    "        line_no = frame.f_lineno\n",
    "        key = func_filename + \".\" + func_name + \":\" + str(line_no)\n",
    "        if config[\"outputType\"] == Outputs.LINES:\n",
    "            lines.append(key)\n",
    "\n",
    "\n",
    "def phase_data():\n",
    "    if config[\"phaseType\"] == PhaseData.STACK_DEPTH:\n",
    "        return len(inspect.stack())\n",
    "    process = psutil.Process(os.getpid())\n",
    "    if config[\"phaseType\"] == PhaseData.MEM_USAGE:\n",
    "        return process.memory_info().rss / (1024 * 1024)  # Convert bytes to MB\n",
    "\n",
    "\n",
    "def trace_calls(frame, event, arg):\n",
    "    if event != \"call\":\n",
    "        return\n",
    "    co = frame.f_code\n",
    "    func_filename = os.path.abspath(co.co_filename)  # Absolute path\n",
    "\n",
    "    # Exclude system libraries and third-party packages\n",
    "    if is_system_code(func_filename):\n",
    "        return\n",
    "\n",
    "    if not config[\"fileNameFilter\"] in func_filename:\n",
    "        return\n",
    "\n",
    "    caller = frame.f_back\n",
    "    caller_func = caller.f_code.co_name\n",
    "    caller_filename = os.path.basename(caller.f_code.co_filename)\n",
    "    key = caller_filename + \".\" + caller_func\n",
    "    value = os.path.basename(func_filename) + \".\" + co.co_name\n",
    "    if config[\"outputType\"] == Outputs.PHASES:\n",
    "        to_write = phase_data()\n",
    "        phases.append((key, to_write))\n",
    "    elif config[\"outputType\"] == Outputs.CALLS:\n",
    "        add_to_set(trace, key, value)\n",
    "    return trace_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360985da3be43c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tracing CovaSim\n",
    "\n",
    "## Tracing each line\n",
    "\n",
    "The following block shows how the tracer can be attached to a piece of code. Here we run our CovaSim case study system. This code will record each line executed, and add it to array lines[].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd5c471f5e32a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import covasim as cv\n",
    "\n",
    "reset()  # Make sure that all of our data-structures for recording trace events are empty.\n",
    "\n",
    "config[\"outputType\"] = Outputs.LINES\n",
    "\n",
    "# Set up the system we want to trace.\n",
    "sim = cv.Sim()\n",
    "\n",
    "# Attach the \"trace_calls\" method defined in the previous block to the system.\n",
    "sys.settrace(trace_calls)\n",
    "\n",
    "# Run the system we want to trace.\n",
    "sim.run()\n",
    "\n",
    "# Detatch the tracer after the execution is complete.\n",
    "sys.settrace(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbda5c4d7f8e58",
   "metadata": {},
   "source": [
    "How big do you reckon the trace is? How many times was a line execution recorded?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fcc45642a76427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate runtime: 583ms\n",
    "print(\"number of lines: \", len(lines))\n",
    "\n",
    "reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6437189f922ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Building a Call graph\n",
    "\n",
    "Now we repeat the above exercise, but instead of recording each line, we record each call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c32885fcf82e7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import covasim as cv\n",
    "\n",
    "\n",
    "reset()\n",
    "\n",
    "# We can choose any of our four types of output - here we choose a CSV file.\n",
    "config[\"outputType\"] = Outputs.CALLS\n",
    "\n",
    "# Set up the system we want to trace.\n",
    "sim = cv.Sim()\n",
    "\n",
    "# Attach the \"trace_calls\" method defined in the previous block to the system.\n",
    "sys.settrace(trace_calls)\n",
    "\n",
    "# Run the system we want to trace.\n",
    "sim.run()\n",
    "\n",
    "# Detatch the tracer after the execution is complete.\n",
    "sys.settrace(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340d768970ff9e6",
   "metadata": {},
   "source": [
    "## Visualising the call graph\n",
    "\n",
    "### As a DOT graph\n",
    "\n",
    "Our calls are recorded as a dictionary, where keys are functions, and values are lists of functions to which calls have been recorded.\n",
    "We can easily build these as a GraphViz graph using the Python GraphViz library.\n",
    "\n",
    "This requires GraphViz to be installed on your local path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5657da1f339dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "\n",
    "def build_graph():\n",
    "    graph = graphviz.Digraph(format=\"png\")\n",
    "\n",
    "    for key, value in trace.items():\n",
    "        for v in value:\n",
    "            if \".py\" in key and \".py\" in v:\n",
    "                graph.edge(f'\"{key}\"', f'\"{v}\"')\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    graph = build_graph()\n",
    "\n",
    "    # Display in Jupyter Notebook\n",
    "    display(graph)\n",
    "\n",
    "    # Save as PDF\n",
    "    output_filename = \"callgraph\"\n",
    "    graph.render(output_filename, format=\"pdf\", cleanup=True)\n",
    "    print(f\"Graph saved as {output_filename}.pdf\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e74695e0d7f90d",
   "metadata": {},
   "source": [
    "### As a graph using NetworkX and matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45faf4008da4ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def build_call_graph(trace):\n",
    "    G = nx.DiGraph()  # Create a directed graph\n",
    "\n",
    "    for caller, callees in trace.items():\n",
    "        for callee in callees:\n",
    "            G.add_edge(caller, callee)  # Add directed edge\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "# Example: Convert trace to a graph\n",
    "G = build_call_graph(trace)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "# pos = nx.circular_layout(G)\n",
    "pos = nx.spring_layout(G, k=0.3)\n",
    "# pos = nx.kamada_kawai_layout(G)\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_color=\"lightgreen\",\n",
    "    edge_color=\"gray\",\n",
    "    font_size=8,\n",
    "    node_size=1,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972a0537d876447",
   "metadata": {},
   "source": [
    "## Focussing only on calls between classes\n",
    "\n",
    "The graph created previously focusses on method-to-method calls. However, sometimes, especially for Reengineering, we are interested in the relationship between classes. Which classes are especially \"close\" to each other. Which pairs of classes might exhibit \"feature envy\"? In this graph we take exactly the same call data as above, but restrict nodes to the classes containing the methods, instead of the individual methods themselves.\n",
    "\n",
    "This generates a different html file (in the root directory of your repository) that you can open in a web browser. To see and open the file, you may need to right-click on the \"week5\" directory in PyCharm, and click \"reload from disk\" to update the contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45674d9bde1c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def merge_nodes_by_prefix(trace):\n",
    "    G = nx.DiGraph()  # Create a directed graph\n",
    "    node_mapping = {}  # Maps full node names to their merged \"x\" component\n",
    "    edge_weights = {}  # Stores edge weights (number of calls)\n",
    "\n",
    "    def get_prefix(name):\n",
    "        return name.split(\".\")[0]  # Extract only the 'x' part\n",
    "\n",
    "    # Step 1: Map all nodes to their merged group and count edges\n",
    "    for caller, callees in trace.items():\n",
    "        caller_group = get_prefix(caller)\n",
    "        node_mapping[caller] = caller_group  # Store mapped value\n",
    "\n",
    "        for callee in callees:\n",
    "            callee_group = get_prefix(callee)\n",
    "            node_mapping[callee] = callee_group\n",
    "            if callee_group == caller_group:\n",
    "                continue\n",
    "            # Count occurrences of edges\n",
    "            edge = (caller_group, callee_group)\n",
    "            edge_weights[edge] = edge_weights.get(edge, 0) + 0.5\n",
    "\n",
    "    # Step 2: Add merged edges to the graph\n",
    "    for (src, dst), weight in edge_weights.items():\n",
    "        G.add_edge(src, dst, weight=weight)  # Store weight in edge attributes\n",
    "\n",
    "    return G, edge_weights\n",
    "\n",
    "\n",
    "# Example: Convert trace to a grouped call graph\n",
    "ClassGraph, edge_weights = merge_nodes_by_prefix(trace)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(15, 15))\n",
    "pos = nx.circular_layout(ClassGraph)\n",
    "\n",
    "# Extract edge weights for visualization\n",
    "edge_widths = [edge_weights[edge] * 2 for edge in ClassGraph.edges()]  # Scale thickness\n",
    "\n",
    "nx.draw(\n",
    "    ClassGraph,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_color=\"lightblue\",\n",
    "    edge_color=\"gray\",\n",
    "    font_size=10,\n",
    "    node_size=2000,\n",
    "    width=edge_widths,\n",
    ")  # Apply edge thickness\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2381550aac8f05",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Carrying out software reconnaissance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca6b6c9a021a9d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following code shows how we can use our tracer to carry out Software Reconnaissance. In this case we home in on a particular piece of functionality within CovaSim: The ability to export results to Excel files. We know that the whole trace for this will include lots of activity which is not specific to excel, such as simply building a Python data-frame in the first place.\n",
    "\n",
    "For software reconnaissance, we therefore build two traces. One trace containing the functionality that we are interested in (exporting to Excel), and one containing the activity that we are not interested in (converting to a dataframe).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c50f12de8ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset()\n",
    "\n",
    "# For this we'll need to collect traces on a line-by-line basis.\n",
    "config[\"outputType\"] = Outputs.LINES\n",
    "\n",
    "# We define our \"positive\" and \"negative\" sets of elements.\n",
    "positive = set()\n",
    "negative = set()\n",
    "\n",
    "# Attach our tracer.\n",
    "sys.settrace(trace_calls)\n",
    "\n",
    "# We run CovaSim - for our positive trace we run the code that converts a simulation to an excel spreadsheet.\n",
    "sim.to_excel()\n",
    "\n",
    "# We want to stop tracing now.\n",
    "sys.settrace(None)\n",
    "\n",
    "# Add all of the lines encountered to the positive set.\n",
    "for element in lines:\n",
    "    positive.add(element)\n",
    "\n",
    "# Start our next trace from an empty list of lines.\n",
    "lines = []\n",
    "\n",
    "# Reactivate the tracer.\n",
    "sys.settrace(trace_calls)\n",
    "\n",
    "# This time, for our negative trace, we run the code to convert output to an conventional Python Dataframe.\n",
    "sim.to_df()\n",
    "\n",
    "# We want to stop tracing now.\n",
    "sys.settrace(None)\n",
    "\n",
    "# Add all of the lines encountered to the positive set.\n",
    "for element in lines:\n",
    "    negative.add(element)\n",
    "\n",
    "print(\"Positive:\" + str(len(positive)) + \" elements in set\")\n",
    "print(\"Negative:\" + str(len(negative)) + \" elements in set\")\n",
    "\n",
    "feature = positive.difference(negative)\n",
    "\n",
    "print(\"Feature:\" + str(len(feature)) + \" elements in set\")\n",
    "\n",
    "print(\"\\n\\nFeature elements:\")\n",
    "for f in feature:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316dd660c3af9212",
   "metadata": {},
   "source": [
    "# Extracting metrics from a call graph\n",
    "\n",
    "When it comes to metrics, there are some metrics (those that rely on the class diagram) that are virtually impossible to compute from Python via static analysis.\n",
    "\n",
    "However, if we are using dynamic analysis, computing these metrics from the dynamic call graph is easy!\n",
    "\n",
    "Here is an example of how to compute the Fan-in and Fan-out metrics for each class. Note the fact that the \"top-level\" classes will tend to have a low fan-in and a high fan-out (c.f. \"Sim\"). On the other hand, low level utility classes (c.f. utils) have a high fan-in and a low fan-out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585cf916009b8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ClassGraph.nodes)\n",
    "for node in ClassGraph.nodes:\n",
    "    print(\n",
    "        node,\n",
    "        \"Fan-in: \",\n",
    "        ClassGraph.in_degree[node],\n",
    "        \"Fan-out: \",\n",
    "        ClassGraph.out_degree[node],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d83c56136d520d",
   "metadata": {},
   "source": [
    "# Phase analysis\n",
    "\n",
    "One of the items we covered in the \"Applied Dynamic Analysis\" lecture was phase analysis. Here we provide an example of what this might look like. When tracing the program, when we encounter a call we can record some aspect of the call that might interest us. This might be the stack-depth, or some other feature (e.g. memory usage). When looking at these as a time-series (i.e. plotting them as a line) it can highlight distinctive patterns or \"phases\" that can point to types of activity during an execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59ba9e444813eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import covasim as cv\n",
    "\n",
    "\n",
    "reset()\n",
    "\n",
    "# We can choose any of our four types of output - here we choose a CSV file.\n",
    "config[\"outputType\"] = Outputs.PHASES\n",
    "\n",
    "config[\"phaseType\"] = PhaseData.STACK_DEPTH\n",
    "\n",
    "# Set up the system we want to trace.\n",
    "sim = cv.Sim()\n",
    "\n",
    "# Attach the \"trace_calls\" method defined in the previous block to the system.\n",
    "sys.settrace(trace_calls)\n",
    "\n",
    "# Run the system we want to trace.\n",
    "sim.run()\n",
    "\n",
    "# Detatch the tracer after the execution is complete.\n",
    "sys.settrace(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dd43fa97bba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Extract keys (labels) and numerical values, ignoring the first element in tuples\n",
    "keys = [key for key, _ in phases]\n",
    "values = [val for _, val in phases]\n",
    "\n",
    "# Create a DataFrame with time index\n",
    "df = pd.DataFrame({\"Step\": range(1, len(values) + 1), \"Value\": values, \"Label\": keys})\n",
    "\n",
    "# Normalize values for color mapping\n",
    "df[\"Color\"] = (df[\"Value\"] - df[\"Value\"].min()) / (df[\"Value\"].max() - df[\"Value\"].min())\n",
    "\n",
    "# Create the plot with labels in hover text\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"Step\",\n",
    "    y=\"Value\",\n",
    "    color=\"Value\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    hover_data={\"Label\": True, \"Step\": False, \"Value\": True},  # Show 'Label' on hover\n",
    "    labels={\"Value\": \"Phase Data\"},\n",
    "    title=\"Phase Data Over Time\",\n",
    ")\n",
    "\n",
    "# Add line to connect points\n",
    "fig.add_trace(px.line(df, x=\"Step\", y=\"Value\").data[0])\n",
    "\n",
    "fig.write_html(\"phase_data.html\")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bee7951357287",
   "metadata": {},
   "source": [
    "## Advanced Topic: Motif detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653b8034d2537ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stumpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example time-series data (Replace this with your own)\n",
    "time_series = np.array(values, dtype=np.float64)\n",
    "\n",
    "matrix_profile = stumpy.stump(time_series, m=500)\n",
    "\n",
    "# Step 3: Find all motifs (subsequences with distance below threshold)\n",
    "motif_locations = []\n",
    "for i, dist in enumerate(matrix_profile[:, 0]):\n",
    "    if dist == 0:\n",
    "        motif_locations.append(i)  # Store indices of motifs\n",
    "\n",
    "# Step 4: Plot the Time-Series with All Motifs Highlighted\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label=\"Time-Series\")\n",
    "\n",
    "# Highlight all motif occurrences\n",
    "for motif in motif_locations:\n",
    "    plt.scatter(motif, time_series[motif], color=\"red\", s=50)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Motif Discovery in Time-Series (All Occurrences)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reeng-w5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
